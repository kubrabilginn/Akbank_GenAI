{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ADIM 1.1: Kütüphaneleri Yükleme (Tekrar)\n",
        "!pip install -q langchain langchain-chroma langchain-google-genai datasets pandas streamlit\n",
        "print(\"✅ Kütüphaneler yüklendi.\")\n",
        "\n",
        "# ADIM 1.2: API Anahtarını GİRİN\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Anahtarı tekrar isteyelim\n",
        "API_KEY = getpass.getpass(\"Lütfen Gemini API Anahtarınızı buraya yapıştırın: \")\n",
        "\n",
        "# Not: Anahtarı os.environ'a da atıyoruz, ancak 3. ve 4. adımlarda direkt kullanacağız.\n",
        "os.environ[\"GEMINI_API_KEY\"] = API_KEY\n",
        "\n",
        "print(\"✅ API Anahtarı yüklendi. (Görünmez kalacaktır)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALbTNwdYVm1v",
        "outputId": "da09b178-6aa4-43b2-f52e-d6b88524dd48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Kütüphaneler yüklendi.\n",
            "Lütfen Gemini API Anahtarınızı buraya yapıştırın: ··········\n",
            "✅ API Anahtarı yüklendi. (Görünmez kalacaktır)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Veri setini yükleme (Sadece ilk 200 satır)\n",
        "try:\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "except Exception as e:\n",
        "    print(f\"Hata: Veri seti yüklenirken veya dönüştürülürken sorun oluştu: {e}\")\n",
        "    # Eğer hata alırsanız, bu kısmı kontrol edin.\n",
        "\n",
        "# Doğru sütun adlarını kullanarak RAG için metin belgesi oluşturma.\n",
        "# Düzeltilmiş sütun adları: 'Title', 'Ingredients', 'Instructions'\n",
        "df['full_recipe'] = df.apply(\n",
        "    lambda row: f\"TARİF ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# RAG için kullanılacak belge listesi\n",
        "recipe_docs = df['full_recipe'].tolist()\n",
        "\n",
        "print(f\"✅ Toplam {len(recipe_docs)} adet tarif belgesi başarıyla hazırlandı.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Örnek Belge Başlangıcı:\")\n",
        "print(recipe_docs[0][:250] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e497a4-a094-4435-b676-3fc3f36231d0",
        "id": "W2IlUwZZWBO1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Toplam 200 adet tarif belgesi başarıyla hazırlandı.\n",
            "--------------------------------------------------\n",
            "Örnek Belge Başlangıcı:\n",
            "TARİF ADI: Miso-Butter Roast Chicken With Acorn Squash Panzanella\n",
            "MALZEMELER: [, ', 1,  , (, 3, ½, –, 4, -, l, b, ., ),  , w, h, o, l, e,  , c, h, i, c, k, e, n, ', ,,  , ', 2, ¾,  , t, s, p, .,  , k, o, s, h, e, r,  , s, a, l, t, ,,  , d, i, v, i, d...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Daha önce getpass ile aldığımız anahtarı kullanıyoruz\n",
        "if 'API_KEY' not in globals():\n",
        "    raise ValueError(\"API_KEY değişkeni bulunamadı. Lütfen 1. Adımı tekrar çalıştırın.\")\n",
        "\n",
        "# 3.1 Embedding Modelini ve Vektör Veritabanını Tanımlama\n",
        "# DÜZELTME: Anahtarı doğrudan 'google_api_key' parametresi ile geçiyoruz.\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"text-embedding-004\",\n",
        "    google_api_key=API_KEY # KESİN ÇÖZÜM BURASI\n",
        ")\n",
        "\n",
        "print(\"Embedding model oluşturuluyor...\")\n",
        "# ChromaDB'yi oluşturma ve belgeleri yükleme (Bu adım Embedding modelini kullanır ve hata bu adımda çıkıyordu)\n",
        "vectorstore = Chroma.from_texts(\n",
        "    texts=recipe_docs,\n",
        "    embedding=embedding_model,\n",
        "    collection_name=\"yemek_tarifleri_rag\"\n",
        ")\n",
        "\n",
        "# Retriever'ı tanımlama\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 3.2 LLM ve Prompt Tanımlama\n",
        "# DÜZELTME: LLM için de anahtarı doğrudan geçiriyoruz.\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.2,\n",
        "    google_api_key=API_KEY # KESİN ÇÖZÜM BURASI\n",
        ")\n",
        "\n",
        "# LLM'ye bağlamı ve talimatı ileten custom prompt\n",
        "PROMPT_TEMPLATE = \"\"\"Aşağıdaki bağlamda sana verilen yemek tariflerini kullanarak, kullanıcının sorusuna detaylı ve yardımcı bir şekilde yanıt ver.\n",
        "Eğer bağlamda uygun tarif bulamazsan, kibarca sadece \"Üzgünüm, veri tabanımda bu isteğe uygun bir tarif bulamadım.\" diye yanıtla ve dışarıdan bilgi ekleme.\n",
        "\n",
        "BAĞLAM:\n",
        "{context}\n",
        "\n",
        "SORU: {question}\n",
        "YANIT:\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "# 3.3 RAG Zincirini Kurma\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"✅ RAG Mimarisi (Embedding, ChromaDB, Retriever, LangChain) başarıyla kuruldu ve API Anahtarı sorunu çözüldü.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alzM2FW9WFMj",
        "outputId": "d0aab5fd-2e94-4729-be8a-a95d9f22079b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model oluşturuluyor...\n",
            "✅ RAG Mimarisi (Embedding, ChromaDB, Retriever, LangChain) başarıyla kuruldu ve API Anahtarı sorunu çözüldü.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# LangChain bileşenleri\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. RAG Bileşenlerini Tanımlama ve Yükleme (Cache ile hızlandırıldı)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# ⚠️ ÖNEMLİ: API Anahtarı, uygulamanın dağıtım ortamında (Streamlit Cloud, vb.)\n",
        "# Güvenli Depolama (Secrets) yoluyla sağlanmalıdır. Colab'de direkt os.environ'dan alır.\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    st.error(\"❌ API Anahtarı bulunamadı. Lütfen Colab'de GEMINI_API_KEY değişkenini ayarlayın.\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# LLM ve Embedding Modelini Tanımlama (Doğrudan API Anahtarı ile)\n",
        "@st.cache_resource\n",
        "def get_llm_model():\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "@st.cache_resource\n",
        "def get_embedding_model():\n",
        "    return GoogleGenerativeAIEmbeddings(\n",
        "        model=\"text-embedding-004\",\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "# 2. Veri Seti Yükleme ve Hazırlama (Dağıtım sırasında veriyi uygulamaya dahil eder)\n",
        "@st.cache_data\n",
        "def load_and_prepare_data():\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "    df['full_recipe'] = df.apply(\n",
        "        lambda row: f\"TARİF ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    return df['full_recipe'].tolist()\n",
        "\n",
        "# 3. Vektör Veritabanı ve Retriever'ı Yükleme/Oluşturma\n",
        "@st.cache_resource\n",
        "def get_retriever(recipe_docs):\n",
        "    embedding_model = get_embedding_model()\n",
        "    # ChromaDB'yi oluşturma ve belgeleri yükleme\n",
        "    vectorstore = Chroma.from_texts(\n",
        "        texts=recipe_docs,\n",
        "        embedding=embedding_model,\n",
        "        collection_name=\"yemek_tarifleri_rag\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 4. RAG Zincirini Kurma\n",
        "@st.cache_resource\n",
        "def get_qa_chain(retriever):\n",
        "    llm = get_llm_model()\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"Aşağıdaki bağlamda sana verilen yemek tariflerini kullanarak, kullanıcının sorusuna detaylı ve yardımcı bir şekilde yanıt ver.\n",
        "    Eğer bağlamda uygun tarif bulamazsan, kibarca sadece \"Üzgünüm, veri tabanımda bu isteğe uygun bir tarif bulamadım.\" diye yanıtla ve dışarıdan bilgi ekleme.\n",
        "\n",
        "    BAĞLAM:\n",
        "    {context}\n",
        "\n",
        "    SORU: {question}\n",
        "    YANIT:\"\"\"\n",
        "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 5. Streamlit Uygulama Arayüzü\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Veriyi yükle ve RAG bileşenlerini kur\n",
        "recipe_docs = load_and_prepare_data()\n",
        "retriever = get_retriever(recipe_docs)\n",
        "qa_chain = get_qa_chain(retriever)\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
        "st.title(\"🍽️ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
        "st.caption(f\"Veri tabanımızda {len(recipe_docs)} tarif bulunmaktadır. (Gemini 2.5 Flash ile güçlendirilmiştir)\")\n",
        "st.divider()\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# Kullanıcı girişi\n",
        "user_query = st.chat_input(\"Tarif sorunuzu girin (Örn: Ispanak ve peynirle ne yapabilirim?)\")\n",
        "\n",
        "if user_query:\n",
        "    # Kullanıcı sorgusunu kaydet\n",
        "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    with st.spinner(f\"'{user_query}' için tarif aranıyor...\"):\n",
        "        try:\n",
        "            # RAG Zincirini Çalıştırma\n",
        "            response = qa_chain.invoke({\"query\": user_query})\n",
        "            llm_response = response['result']\n",
        "            source_docs = response['source_documents']\n",
        "\n",
        "            # Yanıtı ve kaynakları geçmişe ekleme\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"API hatası: Lütfen API anahtarınızın doğru olduğundan ve servislerin çalıştığından emin olun. Hata: {e}\"\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
        "\n",
        "# Geçmişi gösterme\n",
        "for message in st.session_state.history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"**Kullanılan Kaynak Tarifler:**\")\n",
        "            source_names = [doc.page_content.split('\\n')[0].replace('TARİF ADI: ', '') for doc in message[\"sources\"]]\n",
        "            for name in set(source_names):\n",
        "                st.markdown(f\"**-** *{name}*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ZjNdsSWXTX",
        "outputId": "f5a31d98-bd58-4a75-b146-b710c68d9aa8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "# LangChain bileşenleri\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. API Anahtarının Güvenli Kontrolü\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    st.error(\"❌ API Anahtarı bulunamadı. Lütfen Streamlit Cloud'da 'GEMINI_API_KEY' Secret'ını ayarlayın.\")\n",
        "    st.stop()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. RAG Bileşenleri Tanımları (FONKSİYONLAR BURADA BAŞLAR)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# LLM ve Embedding Modelini Tanımlama (Doğrudan API Anahtarı ile)\n",
        "@st.cache_resource\n",
        "def get_llm_model():\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "@st.cache_resource\n",
        "def get_embedding_model():\n",
        "    return GoogleGenerativeAIEmbeddings(\n",
        "        model=\"text-embedding-004\",\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "# Veri Seti Yükleme ve Hazırlama\n",
        "@st.cache_data\n",
        "def load_and_prepare_data():\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "    df['full_recipe'] = df.apply(\n",
        "        lambda row: f\"TARİF ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    return df['full_recipe'].tolist()\n",
        "\n",
        "# Vektör Veritabanı ve Retriever'ı Yükleme/Oluşturma\n",
        "@st.cache_resource\n",
        "def get_retriever(recipe_docs):\n",
        "    embedding_model = get_embedding_model()\n",
        "    vectorstore = Chroma.from_texts(\n",
        "        texts=recipe_docs,\n",
        "        embedding=embedding_model,\n",
        "        collection_name=\"yemek_tarifleri_rag\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# RAG Zincirini Kurma (Cache dekoratörü kalıcı olarak kaldırıldı)\n",
        "def get_qa_chain(retriever):\n",
        "    llm = get_llm_model()\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"Aşağıdaki bağlamda sana verilen yemek tariflerini kullanarak, kullanıcının sorusuna detaylı ve yardımcı bir şekilde yanıt ver.\n",
        "    Eğer bağlamda uygun tarif bulamazsan, kibarca sadece \"Üzgünüm, veri tabanımda bu isteğe uygun bir tarif bulamadım.\" diye yanıtla ve dışarıdan bilgi ekleme.\n",
        "\n",
        "    BAĞLAM:\n",
        "    {context}\n",
        "\n",
        "    SORU: {question}\n",
        "    YANIT:\"\"\"\n",
        "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3. Streamlit Uygulama Arayüzü (Ana İşlem) - HER ŞEY BURADA BAŞLAR\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3.1 RAG Bileşenlerini Yükleme/Kurma\n",
        "# Bu çağırmalar artık fonksiyon tanımlarının altında yapıldığı için NameError çözüldü.\n",
        "recipe_docs = load_and_prepare_data()\n",
        "retriever = get_retriever(recipe_docs)\n",
        "qa_chain = get_qa_chain(retriever)\n",
        "\n",
        "\n",
        "# 3.2 Arayüz Başlıkları\n",
        "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
        "st.title(\"🍽️ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
        "st.caption(f\"Veri tabanımızda {len(recipe_docs)} tarif bulunmaktadır. (Gemini 2.5 Flash ile güçlendirilmiştir)\")\n",
        "st.divider()\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# Kullanıcı Girişi\n",
        "user_query = st.chat_input(\"Tarif sorunuzu girin (Örn: Ispanak ve peynirle ne yapabilirim?)\")\n",
        "\n",
        "if user_query:\n",
        "    # Kullanıcı sorgusunu kaydet\n",
        "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    with st.spinner(f\"'{user_query}' için tarif aranıyor...\"):\n",
        "        try:\n",
        "            # RAG Zincirini Çalıştırma\n",
        "            response = qa_chain.invoke({\"query\": user_query})\n",
        "            llm_response = response['result']\n",
        "            source_docs = response['source_documents']\n",
        "\n",
        "            # Yanıtı ve kaynakları geçmişe ekleme\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"API Hatası: Lütfen API anahtarınızın Streamlit Secrets'ta doğru ayarlandığından emin olun. Hata: {e}\"\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
        "\n",
        "# Geçmişi gösterme\n",
        "for message in st.session_state.history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        # Yanıtta kullanılan kaynakları göster\n",
        "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"**Kullanılan Kaynak Tarifler:**\")\n",
        "            source_names = [doc.page_content.split('\\n')[0].replace('TARİF ADI: ', '') for doc in message[\"sources\"]]\n",
        "            for name in set(source_names):\n",
        "                st.markdown(f\"**-** *{name}*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJkTVH9-cnHX",
        "outputId": "efa32bf2-bbd2-4025-cecf-8e3d97c088e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ED-HPtepE6",
        "outputId": "1a395fd8-7443-412b-fe7c-8f3b72ca69d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import streamlit as st\n",
            "import os\n",
            "import pandas as pd\n",
            "from datasets import load_dataset\n",
            "# LangChain bileşenleri\n",
            "from langchain_chroma import Chroma\n",
            "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
            "from langchain.chains import RetrievalQA\n",
            "from langchain_google_genai import ChatGoogleGenerativeAI\n",
            "from langchain.prompts import PromptTemplate\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 1. API Anahtarının Güvenli Kontrolü\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
            "\n",
            "if not API_KEY:\n",
            "    st.error(\"❌ API Anahtarı bulunamadı. Lütfen Streamlit Cloud'da 'GEMINI_API_KEY' Secret'ını ayarlayın.\")\n",
            "    st.stop()\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 2. RAG Bileşenleri Tanımları (FONKSİYONLAR BURADA BAŞLAR)\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "# LLM ve Embedding Modelini Tanımlama (Doğrudan API Anahtarı ile)\n",
            "@st.cache_resource\n",
            "def get_llm_model():\n",
            "    return ChatGoogleGenerativeAI(\n",
            "        model=\"gemini-2.5-flash\", \n",
            "        temperature=0.2, \n",
            "        google_api_key=API_KEY \n",
            "    )\n",
            "\n",
            "@st.cache_resource\n",
            "def get_embedding_model():\n",
            "    return GoogleGenerativeAIEmbeddings(\n",
            "        model=\"text-embedding-004\", \n",
            "        google_api_key=API_KEY \n",
            "    )\n",
            "\n",
            "# Veri Seti Yükleme ve Hazırlama\n",
            "@st.cache_data\n",
            "def load_and_prepare_data():\n",
            "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
            "    df = dataset.to_pandas()\n",
            "    df['full_recipe'] = df.apply(\n",
            "        lambda row: f\"TARİF ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
            "        axis=1\n",
            "    )\n",
            "    return df['full_recipe'].tolist()\n",
            "\n",
            "# Vektör Veritabanı ve Retriever'ı Yükleme/Oluşturma\n",
            "@st.cache_resource\n",
            "def get_retriever(recipe_docs):\n",
            "    embedding_model = get_embedding_model()\n",
            "    vectorstore = Chroma.from_texts(\n",
            "        texts=recipe_docs, \n",
            "        embedding=embedding_model, \n",
            "        collection_name=\"yemek_tarifleri_rag\"\n",
            "    )\n",
            "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
            "\n",
            "# RAG Zincirini Kurma (Cache dekoratörü kalıcı olarak kaldırıldı)\n",
            "def get_qa_chain(retriever):\n",
            "    llm = get_llm_model()\n",
            "    \n",
            "    PROMPT_TEMPLATE = \"\"\"Aşağıdaki bağlamda sana verilen yemek tariflerini kullanarak, kullanıcının sorusuna detaylı ve yardımcı bir şekilde yanıt ver. \n",
            "    Eğer bağlamda uygun tarif bulamazsan, kibarca sadece \"Üzgünüm, veri tabanımda bu isteğe uygun bir tarif bulamadım.\" diye yanıtla ve dışarıdan bilgi ekleme.\n",
            "\n",
            "    BAĞLAM:\n",
            "    {context}\n",
            "\n",
            "    SORU: {question}\n",
            "    YANIT:\"\"\"\n",
            "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
            "\n",
            "    return RetrievalQA.from_chain_type(\n",
            "        llm=llm,\n",
            "        chain_type=\"stuff\",\n",
            "        retriever=retriever,\n",
            "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
            "        return_source_documents=True\n",
            "    )\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 3. Streamlit Uygulama Arayüzü (Ana İşlem) - HER ŞEY BURADA BAŞLAR\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "# 3.1 RAG Bileşenlerini Yükleme/Kurma\n",
            "# Bu çağırmalar artık fonksiyon tanımlarının altında yapıldığı için NameError çözüldü.\n",
            "recipe_docs = load_and_prepare_data()\n",
            "retriever = get_retriever(recipe_docs)\n",
            "qa_chain = get_qa_chain(retriever)\n",
            "\n",
            "\n",
            "# 3.2 Arayüz Başlıkları\n",
            "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
            "st.title(\"🍽️ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
            "st.caption(f\"Veri tabanımızda {len(recipe_docs)} tarif bulunmaktadır. (Gemini 2.5 Flash ile güçlendirilmiştir)\")\n",
            "st.divider()\n",
            "\n",
            "if 'history' not in st.session_state:\n",
            "    st.session_state.history = []\n",
            "\n",
            "# Kullanıcı Girişi\n",
            "user_query = st.chat_input(\"Tarif sorunuzu girin (Örn: Ispanak ve peynirle ne yapabilirim?)\")\n",
            "\n",
            "if user_query:\n",
            "    # Kullanıcı sorgusunu kaydet\n",
            "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
            "    \n",
            "    with st.spinner(f\"'{user_query}' için tarif aranıyor...\"):\n",
            "        try:\n",
            "            # RAG Zincirini Çalıştırma\n",
            "            response = qa_chain.invoke({\"query\": user_query})\n",
            "            llm_response = response['result']\n",
            "            source_docs = response['source_documents']\n",
            "\n",
            "            # Yanıtı ve kaynakları geçmişe ekleme\n",
            "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
            "\n",
            "        except Exception as e:\n",
            "            error_msg = f\"API Hatası: Lütfen API anahtarınızın Streamlit Secrets'ta doğru ayarlandığından emin olun. Hata: {e}\"\n",
            "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
            "\n",
            "# Geçmişi gösterme\n",
            "for message in st.session_state.history:\n",
            "    with st.chat_message(message[\"role\"]):\n",
            "        st.markdown(message[\"content\"])\n",
            "        \n",
            "        # Yanıtta kullanılan kaynakları göster\n",
            "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
            "            st.markdown(\"---\")\n",
            "            st.markdown(\"**Kullanılan Kaynak Tarifler:**\")\n",
            "            source_names = [doc.page_content.split('\\n')[0].replace('TARİF ADI: ', '') for doc in message[\"sources\"]]\n",
            "            for name in set(source_names):\n",
            "                st.markdown(f\"**-** *{name}*\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Önceki tünelleri temizleyin\n",
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n",
        "\n",
        "# 1. ngrok authtoken'ı alın\n",
        "NGROK_TOKEN = getpass.getpass(\"Lütfen ngrok Authtoken'ınızı buraya yapıştırın: \")\n",
        "\n",
        "# 2. ngrok'a kimlik doğrulaması yapın\n",
        "# Bu, ngrok'un artık sizin hesabınızla çalışmasını sağlar.\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# 3. Streamlit uygulamasını tekrar başlatın (Önceki kodunuz)\n",
        "print(\"Streamlit uygulamasını arka planda başlatıyor...\")\n",
        "subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.enableCORS\", \"false\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "# 4. Tüneli açın (Bu sefer kimlik doğrulama sorunu yaşanmamalı)\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "\n",
        "    print(\"\\n---------------------------------------------------------\")\n",
        "    print(\"🎉 Streamlit Uygulamanız ÇALIŞIYOR! Geçici Web Linkiniz:\")\n",
        "    print(f\"🔗 {public_url}\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n❌ ngrok tüneli kurulamadı.\")\n",
        "    print(\"Lütfen ngrok token'ınızın doğru olduğundan emin olun.\")\n",
        "    print(\"Hata detayı:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBACHtp6ctKx",
        "outputId": "25eb6a16-104e-40cf-f581-f8871604ad16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lütfen ngrok Authtoken'ınızı buraya yapıştırın: ··········\n",
            "Streamlit uygulamasını arka planda başlatıyor...\n",
            "\n",
            "---------------------------------------------------------\n",
            "🎉 Streamlit Uygulamanız ÇALIŞIYOR! Geçici Web Linkiniz:\n",
            "🔗 NgrokTunnel: \"https://biconically-limnologic-willow.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "langchain-chroma\n",
        "langchain-google-genai\n",
        "datasets\n",
        "pandas\n",
        "streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urmi9Tyie_Jb",
        "outputId": "99e9c1ea-f471-4dbc-9791-55596cbbcb24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1-uwTdgfF2q",
        "outputId": "4c53b53e-d13e-4419-b199-618171fa63d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain\n",
            "langchain-chroma\n",
            "langchain-google-genai\n",
            "datasets\n",
            "pandas\n",
            "streamlit\n"
          ]
        }
      ]
    }
  ]
}