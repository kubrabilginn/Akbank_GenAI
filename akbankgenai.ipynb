{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ADIM 1.1: KÃ¼tÃ¼phaneleri YÃ¼kleme (Tekrar)\n",
        "!pip install -q langchain langchain-chroma langchain-google-genai datasets pandas streamlit\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler yÃ¼klendi.\")\n",
        "\n",
        "# ADIM 1.2: API AnahtarÄ±nÄ± GÄ°RÄ°N\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# AnahtarÄ± tekrar isteyelim\n",
        "API_KEY = getpass.getpass(\"LÃ¼tfen Gemini API AnahtarÄ±nÄ±zÄ± buraya yapÄ±ÅŸtÄ±rÄ±n: \")\n",
        "\n",
        "# Not: AnahtarÄ± os.environ'a da atÄ±yoruz, ancak 3. ve 4. adÄ±mlarda direkt kullanacaÄŸÄ±z.\n",
        "os.environ[\"GEMINI_API_KEY\"] = API_KEY\n",
        "\n",
        "print(\"âœ… API AnahtarÄ± yÃ¼klendi. (GÃ¶rÃ¼nmez kalacaktÄ±r)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALbTNwdYVm1v",
        "outputId": "da09b178-6aa4-43b2-f52e-d6b88524dd48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… KÃ¼tÃ¼phaneler yÃ¼klendi.\n",
            "LÃ¼tfen Gemini API AnahtarÄ±nÄ±zÄ± buraya yapÄ±ÅŸtÄ±rÄ±n: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… API AnahtarÄ± yÃ¼klendi. (GÃ¶rÃ¼nmez kalacaktÄ±r)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Veri setini yÃ¼kleme (Sadece ilk 200 satÄ±r)\n",
        "try:\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "except Exception as e:\n",
        "    print(f\"Hata: Veri seti yÃ¼klenirken veya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼rken sorun oluÅŸtu: {e}\")\n",
        "    # EÄŸer hata alÄ±rsanÄ±z, bu kÄ±smÄ± kontrol edin.\n",
        "\n",
        "# DoÄŸru sÃ¼tun adlarÄ±nÄ± kullanarak RAG iÃ§in metin belgesi oluÅŸturma.\n",
        "# DÃ¼zeltilmiÅŸ sÃ¼tun adlarÄ±: 'Title', 'Ingredients', 'Instructions'\n",
        "df['full_recipe'] = df.apply(\n",
        "    lambda row: f\"TARÄ°F ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# RAG iÃ§in kullanÄ±lacak belge listesi\n",
        "recipe_docs = df['full_recipe'].tolist()\n",
        "\n",
        "print(f\"âœ… Toplam {len(recipe_docs)} adet tarif belgesi baÅŸarÄ±yla hazÄ±rlandÄ±.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Ã–rnek Belge BaÅŸlangÄ±cÄ±:\")\n",
        "print(recipe_docs[0][:250] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e497a4-a094-4435-b676-3fc3f36231d0",
        "id": "W2IlUwZZWBO1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Toplam 200 adet tarif belgesi baÅŸarÄ±yla hazÄ±rlandÄ±.\n",
            "--------------------------------------------------\n",
            "Ã–rnek Belge BaÅŸlangÄ±cÄ±:\n",
            "TARÄ°F ADI: Miso-Butter Roast Chicken With Acorn Squash Panzanella\n",
            "MALZEMELER: [, ', 1,  , (, 3, Â½, â€“, 4, -, l, b, ., ),  , w, h, o, l, e,  , c, h, i, c, k, e, n, ', ,,  , ', 2, Â¾,  , t, s, p, .,  , k, o, s, h, e, r,  , s, a, l, t, ,,  , d, i, v, i, d...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Daha Ã¶nce getpass ile aldÄ±ÄŸÄ±mÄ±z anahtarÄ± kullanÄ±yoruz\n",
        "if 'API_KEY' not in globals():\n",
        "    raise ValueError(\"API_KEY deÄŸiÅŸkeni bulunamadÄ±. LÃ¼tfen 1. AdÄ±mÄ± tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
        "\n",
        "# 3.1 Embedding Modelini ve VektÃ¶r VeritabanÄ±nÄ± TanÄ±mlama\n",
        "# DÃœZELTME: AnahtarÄ± doÄŸrudan 'google_api_key' parametresi ile geÃ§iyoruz.\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"text-embedding-004\",\n",
        "    google_api_key=API_KEY # KESÄ°N Ã‡Ã–ZÃœM BURASI\n",
        ")\n",
        "\n",
        "print(\"Embedding model oluÅŸturuluyor...\")\n",
        "# ChromaDB'yi oluÅŸturma ve belgeleri yÃ¼kleme (Bu adÄ±m Embedding modelini kullanÄ±r ve hata bu adÄ±mda Ã§Ä±kÄ±yordu)\n",
        "vectorstore = Chroma.from_texts(\n",
        "    texts=recipe_docs,\n",
        "    embedding=embedding_model,\n",
        "    collection_name=\"yemek_tarifleri_rag\"\n",
        ")\n",
        "\n",
        "# Retriever'Ä± tanÄ±mlama\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 3.2 LLM ve Prompt TanÄ±mlama\n",
        "# DÃœZELTME: LLM iÃ§in de anahtarÄ± doÄŸrudan geÃ§iriyoruz.\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.2,\n",
        "    google_api_key=API_KEY # KESÄ°N Ã‡Ã–ZÃœM BURASI\n",
        ")\n",
        "\n",
        "# LLM'ye baÄŸlamÄ± ve talimatÄ± ileten custom prompt\n",
        "PROMPT_TEMPLATE = \"\"\"AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver.\n",
        "EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece \"ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m.\" diye yanÄ±tla ve dÄ±ÅŸarÄ±dan bilgi ekleme.\n",
        "\n",
        "BAÄžLAM:\n",
        "{context}\n",
        "\n",
        "SORU: {question}\n",
        "YANIT:\"\"\"\n",
        "\n",
        "custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "# 3.3 RAG Zincirini Kurma\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"âœ… RAG Mimarisi (Embedding, ChromaDB, Retriever, LangChain) baÅŸarÄ±yla kuruldu ve API AnahtarÄ± sorunu Ã§Ã¶zÃ¼ldÃ¼.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alzM2FW9WFMj",
        "outputId": "d0aab5fd-2e94-4729-be8a-a95d9f22079b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model oluÅŸturuluyor...\n",
            "âœ… RAG Mimarisi (Embedding, ChromaDB, Retriever, LangChain) baÅŸarÄ±yla kuruldu ve API AnahtarÄ± sorunu Ã§Ã¶zÃ¼ldÃ¼.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# LangChain bileÅŸenleri\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. RAG BileÅŸenlerini TanÄ±mlama ve YÃ¼kleme (Cache ile hÄ±zlandÄ±rÄ±ldÄ±)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# âš ï¸ Ã–NEMLÄ°: API AnahtarÄ±, uygulamanÄ±n daÄŸÄ±tÄ±m ortamÄ±nda (Streamlit Cloud, vb.)\n",
        "# GÃ¼venli Depolama (Secrets) yoluyla saÄŸlanmalÄ±dÄ±r. Colab'de direkt os.environ'dan alÄ±r.\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    st.error(\"âŒ API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Colab'de GEMINI_API_KEY deÄŸiÅŸkenini ayarlayÄ±n.\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# LLM ve Embedding Modelini TanÄ±mlama (DoÄŸrudan API AnahtarÄ± ile)\n",
        "@st.cache_resource\n",
        "def get_llm_model():\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "@st.cache_resource\n",
        "def get_embedding_model():\n",
        "    return GoogleGenerativeAIEmbeddings(\n",
        "        model=\"text-embedding-004\",\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "# 2. Veri Seti YÃ¼kleme ve HazÄ±rlama (DaÄŸÄ±tÄ±m sÄ±rasÄ±nda veriyi uygulamaya dahil eder)\n",
        "@st.cache_data\n",
        "def load_and_prepare_data():\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "    df['full_recipe'] = df.apply(\n",
        "        lambda row: f\"TARÄ°F ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    return df['full_recipe'].tolist()\n",
        "\n",
        "# 3. VektÃ¶r VeritabanÄ± ve Retriever'Ä± YÃ¼kleme/OluÅŸturma\n",
        "@st.cache_resource\n",
        "def get_retriever(recipe_docs):\n",
        "    embedding_model = get_embedding_model()\n",
        "    # ChromaDB'yi oluÅŸturma ve belgeleri yÃ¼kleme\n",
        "    vectorstore = Chroma.from_texts(\n",
        "        texts=recipe_docs,\n",
        "        embedding=embedding_model,\n",
        "        collection_name=\"yemek_tarifleri_rag\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 4. RAG Zincirini Kurma\n",
        "@st.cache_resource\n",
        "def get_qa_chain(retriever):\n",
        "    llm = get_llm_model()\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver.\n",
        "    EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece \"ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m.\" diye yanÄ±tla ve dÄ±ÅŸarÄ±dan bilgi ekleme.\n",
        "\n",
        "    BAÄžLAM:\n",
        "    {context}\n",
        "\n",
        "    SORU: {question}\n",
        "    YANIT:\"\"\"\n",
        "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 5. Streamlit Uygulama ArayÃ¼zÃ¼\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Veriyi yÃ¼kle ve RAG bileÅŸenlerini kur\n",
        "recipe_docs = load_and_prepare_data()\n",
        "retriever = get_retriever(recipe_docs)\n",
        "qa_chain = get_qa_chain(retriever)\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
        "st.title(\"ðŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
        "st.caption(f\"Veri tabanÄ±mÄ±zda {len(recipe_docs)} tarif bulunmaktadÄ±r. (Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir)\")\n",
        "st.divider()\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# KullanÄ±cÄ± giriÅŸi\n",
        "user_query = st.chat_input(\"Tarif sorunuzu girin (Ã–rn: Ispanak ve peynirle ne yapabilirim?)\")\n",
        "\n",
        "if user_query:\n",
        "    # KullanÄ±cÄ± sorgusunu kaydet\n",
        "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    with st.spinner(f\"'{user_query}' iÃ§in tarif aranÄ±yor...\"):\n",
        "        try:\n",
        "            # RAG Zincirini Ã‡alÄ±ÅŸtÄ±rma\n",
        "            response = qa_chain.invoke({\"query\": user_query})\n",
        "            llm_response = response['result']\n",
        "            source_docs = response['source_documents']\n",
        "\n",
        "            # YanÄ±tÄ± ve kaynaklarÄ± geÃ§miÅŸe ekleme\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"API hatasÄ±: LÃ¼tfen API anahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸundan ve servislerin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun. Hata: {e}\"\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
        "\n",
        "# GeÃ§miÅŸi gÃ¶sterme\n",
        "for message in st.session_state.history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"**KullanÄ±lan Kaynak Tarifler:**\")\n",
        "            source_names = [doc.page_content.split('\\n')[0].replace('TARÄ°F ADI: ', '') for doc in message[\"sources\"]]\n",
        "            for name in set(source_names):\n",
        "                st.markdown(f\"**-** *{name}*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ZjNdsSWXTX",
        "outputId": "f5a31d98-bd58-4a75-b146-b710c68d9aa8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "# LangChain bileÅŸenleri\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. API AnahtarÄ±nÄ±n GÃ¼venli KontrolÃ¼\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    st.error(\"âŒ API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Cloud'da 'GEMINI_API_KEY' Secret'Ä±nÄ± ayarlayÄ±n.\")\n",
        "    st.stop()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. RAG BileÅŸenleri TanÄ±mlarÄ± (FONKSÄ°YONLAR BURADA BAÅžLAR)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# LLM ve Embedding Modelini TanÄ±mlama (DoÄŸrudan API AnahtarÄ± ile)\n",
        "@st.cache_resource\n",
        "def get_llm_model():\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        temperature=0.2,\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "@st.cache_resource\n",
        "def get_embedding_model():\n",
        "    return GoogleGenerativeAIEmbeddings(\n",
        "        model=\"text-embedding-004\",\n",
        "        google_api_key=API_KEY\n",
        "    )\n",
        "\n",
        "# Veri Seti YÃ¼kleme ve HazÄ±rlama\n",
        "@st.cache_data\n",
        "def load_and_prepare_data():\n",
        "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
        "    df = dataset.to_pandas()\n",
        "    df['full_recipe'] = df.apply(\n",
        "        lambda row: f\"TARÄ°F ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    return df['full_recipe'].tolist()\n",
        "\n",
        "# VektÃ¶r VeritabanÄ± ve Retriever'Ä± YÃ¼kleme/OluÅŸturma\n",
        "@st.cache_resource\n",
        "def get_retriever(recipe_docs):\n",
        "    embedding_model = get_embedding_model()\n",
        "    vectorstore = Chroma.from_texts(\n",
        "        texts=recipe_docs,\n",
        "        embedding=embedding_model,\n",
        "        collection_name=\"yemek_tarifleri_rag\"\n",
        "    )\n",
        "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# RAG Zincirini Kurma (Cache dekoratÃ¶rÃ¼ kalÄ±cÄ± olarak kaldÄ±rÄ±ldÄ±)\n",
        "def get_qa_chain(retriever):\n",
        "    llm = get_llm_model()\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver.\n",
        "    EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece \"ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m.\" diye yanÄ±tla ve dÄ±ÅŸarÄ±dan bilgi ekleme.\n",
        "\n",
        "    BAÄžLAM:\n",
        "    {context}\n",
        "\n",
        "    SORU: {question}\n",
        "    YANIT:\"\"\"\n",
        "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3. Streamlit Uygulama ArayÃ¼zÃ¼ (Ana Ä°ÅŸlem) - HER ÅžEY BURADA BAÅžLAR\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# 3.1 RAG BileÅŸenlerini YÃ¼kleme/Kurma\n",
        "# Bu Ã§aÄŸÄ±rmalar artÄ±k fonksiyon tanÄ±mlarÄ±nÄ±n altÄ±nda yapÄ±ldÄ±ÄŸÄ± iÃ§in NameError Ã§Ã¶zÃ¼ldÃ¼.\n",
        "recipe_docs = load_and_prepare_data()\n",
        "retriever = get_retriever(recipe_docs)\n",
        "qa_chain = get_qa_chain(retriever)\n",
        "\n",
        "\n",
        "# 3.2 ArayÃ¼z BaÅŸlÄ±klarÄ±\n",
        "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
        "st.title(\"ðŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
        "st.caption(f\"Veri tabanÄ±mÄ±zda {len(recipe_docs)} tarif bulunmaktadÄ±r. (Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir)\")\n",
        "st.divider()\n",
        "\n",
        "if 'history' not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# KullanÄ±cÄ± GiriÅŸi\n",
        "user_query = st.chat_input(\"Tarif sorunuzu girin (Ã–rn: Ispanak ve peynirle ne yapabilirim?)\")\n",
        "\n",
        "if user_query:\n",
        "    # KullanÄ±cÄ± sorgusunu kaydet\n",
        "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
        "\n",
        "    with st.spinner(f\"'{user_query}' iÃ§in tarif aranÄ±yor...\"):\n",
        "        try:\n",
        "            # RAG Zincirini Ã‡alÄ±ÅŸtÄ±rma\n",
        "            response = qa_chain.invoke({\"query\": user_query})\n",
        "            llm_response = response['result']\n",
        "            source_docs = response['source_documents']\n",
        "\n",
        "            # YanÄ±tÄ± ve kaynaklarÄ± geÃ§miÅŸe ekleme\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"API HatasÄ±: LÃ¼tfen API anahtarÄ±nÄ±zÄ±n Streamlit Secrets'ta doÄŸru ayarlandÄ±ÄŸÄ±ndan emin olun. Hata: {e}\"\n",
        "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
        "\n",
        "# GeÃ§miÅŸi gÃ¶sterme\n",
        "for message in st.session_state.history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "        # YanÄ±tta kullanÄ±lan kaynaklarÄ± gÃ¶ster\n",
        "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"**KullanÄ±lan Kaynak Tarifler:**\")\n",
        "            source_names = [doc.page_content.split('\\n')[0].replace('TARÄ°F ADI: ', '') for doc in message[\"sources\"]]\n",
        "            for name in set(source_names):\n",
        "                st.markdown(f\"**-** *{name}*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJkTVH9-cnHX",
        "outputId": "efa32bf2-bbd2-4025-cecf-8e3d97c088e3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55ED-HPtepE6",
        "outputId": "1a395fd8-7443-412b-fe7c-8f3b72ca69d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import streamlit as st\n",
            "import os\n",
            "import pandas as pd\n",
            "from datasets import load_dataset\n",
            "# LangChain bileÅŸenleri\n",
            "from langchain_chroma import Chroma\n",
            "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
            "from langchain.chains import RetrievalQA\n",
            "from langchain_google_genai import ChatGoogleGenerativeAI\n",
            "from langchain.prompts import PromptTemplate\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 1. API AnahtarÄ±nÄ±n GÃ¼venli KontrolÃ¼\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
            "\n",
            "if not API_KEY:\n",
            "    st.error(\"âŒ API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Cloud'da 'GEMINI_API_KEY' Secret'Ä±nÄ± ayarlayÄ±n.\")\n",
            "    st.stop()\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 2. RAG BileÅŸenleri TanÄ±mlarÄ± (FONKSÄ°YONLAR BURADA BAÅžLAR)\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "# LLM ve Embedding Modelini TanÄ±mlama (DoÄŸrudan API AnahtarÄ± ile)\n",
            "@st.cache_resource\n",
            "def get_llm_model():\n",
            "    return ChatGoogleGenerativeAI(\n",
            "        model=\"gemini-2.5-flash\", \n",
            "        temperature=0.2, \n",
            "        google_api_key=API_KEY \n",
            "    )\n",
            "\n",
            "@st.cache_resource\n",
            "def get_embedding_model():\n",
            "    return GoogleGenerativeAIEmbeddings(\n",
            "        model=\"text-embedding-004\", \n",
            "        google_api_key=API_KEY \n",
            "    )\n",
            "\n",
            "# Veri Seti YÃ¼kleme ve HazÄ±rlama\n",
            "@st.cache_data\n",
            "def load_and_prepare_data():\n",
            "    dataset = load_dataset(\"Hieu-Pham/kaggle_food_recipes\", split=\"train[:200]\")\n",
            "    df = dataset.to_pandas()\n",
            "    df['full_recipe'] = df.apply(\n",
            "        lambda row: f\"TARÄ°F ADI: {row['Title']}\\nMALZEMELER: {', '.join(row['Ingredients'])}\\nADIMLAR: {row['Instructions']}\",\n",
            "        axis=1\n",
            "    )\n",
            "    return df['full_recipe'].tolist()\n",
            "\n",
            "# VektÃ¶r VeritabanÄ± ve Retriever'Ä± YÃ¼kleme/OluÅŸturma\n",
            "@st.cache_resource\n",
            "def get_retriever(recipe_docs):\n",
            "    embedding_model = get_embedding_model()\n",
            "    vectorstore = Chroma.from_texts(\n",
            "        texts=recipe_docs, \n",
            "        embedding=embedding_model, \n",
            "        collection_name=\"yemek_tarifleri_rag\"\n",
            "    )\n",
            "    return vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
            "\n",
            "# RAG Zincirini Kurma (Cache dekoratÃ¶rÃ¼ kalÄ±cÄ± olarak kaldÄ±rÄ±ldÄ±)\n",
            "def get_qa_chain(retriever):\n",
            "    llm = get_llm_model()\n",
            "    \n",
            "    PROMPT_TEMPLATE = \"\"\"AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver. \n",
            "    EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece \"ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m.\" diye yanÄ±tla ve dÄ±ÅŸarÄ±dan bilgi ekleme.\n",
            "\n",
            "    BAÄžLAM:\n",
            "    {context}\n",
            "\n",
            "    SORU: {question}\n",
            "    YANIT:\"\"\"\n",
            "    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)\n",
            "\n",
            "    return RetrievalQA.from_chain_type(\n",
            "        llm=llm,\n",
            "        chain_type=\"stuff\",\n",
            "        retriever=retriever,\n",
            "        chain_type_kwargs={\"prompt\": custom_rag_prompt},\n",
            "        return_source_documents=True\n",
            "    )\n",
            "\n",
            "# ----------------------------------------------------------------------\n",
            "# 3. Streamlit Uygulama ArayÃ¼zÃ¼ (Ana Ä°ÅŸlem) - HER ÅžEY BURADA BAÅžLAR\n",
            "# ----------------------------------------------------------------------\n",
            "\n",
            "# 3.1 RAG BileÅŸenlerini YÃ¼kleme/Kurma\n",
            "# Bu Ã§aÄŸÄ±rmalar artÄ±k fonksiyon tanÄ±mlarÄ±nÄ±n altÄ±nda yapÄ±ldÄ±ÄŸÄ± iÃ§in NameError Ã§Ã¶zÃ¼ldÃ¼.\n",
            "recipe_docs = load_and_prepare_data()\n",
            "retriever = get_retriever(recipe_docs)\n",
            "qa_chain = get_qa_chain(retriever)\n",
            "\n",
            "\n",
            "# 3.2 ArayÃ¼z BaÅŸlÄ±klarÄ±\n",
            "st.set_page_config(page_title=\"Akbank GenAI Yemek Tarifleri Chatbotu\", layout=\"wide\")\n",
            "st.title(\"ðŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)\")\n",
            "st.caption(f\"Veri tabanÄ±mÄ±zda {len(recipe_docs)} tarif bulunmaktadÄ±r. (Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir)\")\n",
            "st.divider()\n",
            "\n",
            "if 'history' not in st.session_state:\n",
            "    st.session_state.history = []\n",
            "\n",
            "# KullanÄ±cÄ± GiriÅŸi\n",
            "user_query = st.chat_input(\"Tarif sorunuzu girin (Ã–rn: Ispanak ve peynirle ne yapabilirim?)\")\n",
            "\n",
            "if user_query:\n",
            "    # KullanÄ±cÄ± sorgusunu kaydet\n",
            "    st.session_state.history.append({\"role\": \"user\", \"content\": user_query})\n",
            "    \n",
            "    with st.spinner(f\"'{user_query}' iÃ§in tarif aranÄ±yor...\"):\n",
            "        try:\n",
            "            # RAG Zincirini Ã‡alÄ±ÅŸtÄ±rma\n",
            "            response = qa_chain.invoke({\"query\": user_query})\n",
            "            llm_response = response['result']\n",
            "            source_docs = response['source_documents']\n",
            "\n",
            "            # YanÄ±tÄ± ve kaynaklarÄ± geÃ§miÅŸe ekleme\n",
            "            st.session_state.history.append({\"role\": \"assistant\", \"content\": llm_response, \"sources\": source_docs})\n",
            "\n",
            "        except Exception as e:\n",
            "            error_msg = f\"API HatasÄ±: LÃ¼tfen API anahtarÄ±nÄ±zÄ±n Streamlit Secrets'ta doÄŸru ayarlandÄ±ÄŸÄ±ndan emin olun. Hata: {e}\"\n",
            "            st.session_state.history.append({\"role\": \"assistant\", \"content\": error_msg, \"sources\": []})\n",
            "\n",
            "# GeÃ§miÅŸi gÃ¶sterme\n",
            "for message in st.session_state.history:\n",
            "    with st.chat_message(message[\"role\"]):\n",
            "        st.markdown(message[\"content\"])\n",
            "        \n",
            "        # YanÄ±tta kullanÄ±lan kaynaklarÄ± gÃ¶ster\n",
            "        if message[\"role\"] == \"assistant\" and \"sources\" in message and message[\"sources\"]:\n",
            "            st.markdown(\"---\")\n",
            "            st.markdown(\"**KullanÄ±lan Kaynak Tarifler:**\")\n",
            "            source_names = [doc.page_content.split('\\n')[0].replace('TARÄ°F ADI: ', '') for doc in message[\"sources\"]]\n",
            "            for name in set(source_names):\n",
            "                st.markdown(f\"**-** *{name}*\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Ã–nceki tÃ¼nelleri temizleyin\n",
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n",
        "\n",
        "# 1. ngrok authtoken'Ä± alÄ±n\n",
        "NGROK_TOKEN = getpass.getpass(\"LÃ¼tfen ngrok Authtoken'Ä±nÄ±zÄ± buraya yapÄ±ÅŸtÄ±rÄ±n: \")\n",
        "\n",
        "# 2. ngrok'a kimlik doÄŸrulamasÄ± yapÄ±n\n",
        "# Bu, ngrok'un artÄ±k sizin hesabÄ±nÄ±zla Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# 3. Streamlit uygulamasÄ±nÄ± tekrar baÅŸlatÄ±n (Ã–nceki kodunuz)\n",
        "print(\"Streamlit uygulamasÄ±nÄ± arka planda baÅŸlatÄ±yor...\")\n",
        "subprocess.Popen(\n",
        "    [\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\", \"--server.enableCORS\", \"false\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "# 4. TÃ¼neli aÃ§Ä±n (Bu sefer kimlik doÄŸrulama sorunu yaÅŸanmamalÄ±)\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "\n",
        "    print(\"\\n---------------------------------------------------------\")\n",
        "    print(\"ðŸŽ‰ Streamlit UygulamanÄ±z Ã‡ALIÅžIYOR! GeÃ§ici Web Linkiniz:\")\n",
        "    print(f\"ðŸ”— {public_url}\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\nâŒ ngrok tÃ¼neli kurulamadÄ±.\")\n",
        "    print(\"LÃ¼tfen ngrok token'Ä±nÄ±zÄ±n doÄŸru olduÄŸundan emin olun.\")\n",
        "    print(\"Hata detayÄ±:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBACHtp6ctKx",
        "outputId": "25eb6a16-104e-40cf-f581-f8871604ad16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LÃ¼tfen ngrok Authtoken'Ä±nÄ±zÄ± buraya yapÄ±ÅŸtÄ±rÄ±n: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Streamlit uygulamasÄ±nÄ± arka planda baÅŸlatÄ±yor...\n",
            "\n",
            "---------------------------------------------------------\n",
            "ðŸŽ‰ Streamlit UygulamanÄ±z Ã‡ALIÅžIYOR! GeÃ§ici Web Linkiniz:\n",
            "ðŸ”— NgrokTunnel: \"https://biconically-limnologic-willow.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "---------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "langchain-chroma\n",
        "langchain-google-genai\n",
        "datasets\n",
        "pandas\n",
        "streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urmi9Tyie_Jb",
        "outputId": "99e9c1ea-f471-4dbc-9791-55596cbbcb24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1-uwTdgfF2q",
        "outputId": "4c53b53e-d13e-4419-b199-618171fa63d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain\n",
            "langchain-chroma\n",
            "langchain-google-genai\n",
            "datasets\n",
            "pandas\n",
            "streamlit\n"
          ]
        }
      ]
    }
  ]
}