import streamlit as st
import os
import pandas as pd
import numpy as np
from typing import List
import traceback # Hata ayÄ±klama iÃ§in

# Hugging Face KÃ¼tÃ¼phaneleri
from huggingface_hub import InferenceClient
from sentence_transformers import SentenceTransformer
from datasets import load_dataset

# ------------------------------------------------
# Hugging Face API Token (Opsiyonel ama Ã–nerilir)
# ------------------------------------------------
HF_TOKEN = os.environ.get("HF_TOKEN")
# if not HF_TOKEN:
#     st.warning("Hugging Face API Token bulunamadÄ±. Ãœcretsiz limitlerle devam ediliyor.")

# Model isimleri
embedding_model_name = 'all-MiniLM-L6-v2'
llm_model_name = "mistralai/Mistral-7B-Instruct-v0.1"

# Hugging Face Inference Client'Ä± baÅŸlatma
try:
    hf_client = InferenceClient(model=llm_model_name, token=HF_TOKEN)
except Exception as e:
    st.error(f"Hugging Face Inference Client baÅŸlatÄ±lÄ±rken hata: {e}")
    st.stop()


# ------------------------------------------------
# Sentence Transformer Modelini YÃ¼kleme (Cache ile)
# ------------------------------------------------
@st.cache_resource(show_spinner="Embedding modeli yÃ¼kleniyor...")
def load_embedding_model():
    """Hugging Face'den Sentence Transformer modelini yÃ¼kler."""
    try:
        model = SentenceTransformer(embedding_model_name)
        return model
    except Exception as e:
        st.error(f"Sentence Transformer modeli yÃ¼klenirken hata: {e}")
        st.stop()

# ------------------------------------------------
# Tarifleri yÃ¼kleme
# ------------------------------------------------
@st.cache_data(show_spinner="Tarifler yÃ¼kleniyor...")
def load_recipes() -> list[str]:
    """
    Hugging Face datasets Ã¼zerinden yemek tariflerini yÃ¼kler.
    Ä°lk 200 tarifi alÄ±r ve Title + Ingredients + Instructions ÅŸeklinde birleÅŸtirir.
    """
    try:
        ds = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
        recipes = []
        for item in ds:
            title = item.get("Title", "")
            ingredients = item.get("Ingredients", [])
            if isinstance(ingredients, list):
                ingredients = ", ".join(ingredients)
            else:
                ingredients = str(ingredients)
            instructions = item.get("Instructions", "")
            full_recipe = f"TARÄ°F ADI: {title}\nMALZEMELER: {ingredients}\nADIMLAR: {instructions}"
            recipes.append(full_recipe)
        if not recipes:
             st.error("Tarifler yÃ¼klenemedi veya veri seti boÅŸ.")
             st.stop()
        return recipes
    except Exception as e:
        st.error(f"Veri seti yÃ¼klenirken hata: {e}")
        st.stop()


# ------------------------------------------------
# Veri ve Embedding Cache (Sentence Transformer ile)
# ------------------------------------------------
@st.cache_data(show_spinner="Veriler ve embeddingler hazÄ±rlanÄ±yor...")
def load_data_and_embeddings(_embedding_model):
    """Tarifleri yÃ¼kler ve Sentence Transformer ile embed eder."""
    recipe_docs = load_recipes()
    if not recipe_docs:
        st.error("Tarif dokÃ¼manlarÄ± boÅŸ, embedding oluÅŸturulamÄ±yor.")
        st.stop()

    doc_ids = [f"doc_{i}" for i in range(len(recipe_docs))]
    try:
        embeds = _embedding_model.encode(recipe_docs, show_progress_bar=False)
        if embeds is None or len(embeds) == 0:
             st.error("Embedding oluÅŸturma baÅŸarÄ±sÄ±z oldu, boÅŸ sonuÃ§ dÃ¶ndÃ¼.")
             st.stop()
        embeds_np = np.array(embeds)
        return recipe_docs, doc_ids, embeds_np
    except Exception as e:
        st.error(f"Embedding oluÅŸturulurken hata: {str(e)}")
        st.stop()


# âœ… KosinÃ¼s benzerliÄŸi
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """Ä°ki NumPy vektÃ¶rÃ¼ arasÄ±ndaki kosinÃ¼s benzerliÄŸini hesaplar."""
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    dot_product = np.dot(a.astype(np.float32), b.astype(np.float32))
    return dot_product / (norm_a * norm_b)

# ------------------------------------------------
# UI
# ------------------------------------------------
st.set_page_config(page_title="Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (HF Embedding + HF LLM)")
st.divider()

# Embedding modelini yÃ¼kle
embedding_model = load_embedding_model()
# Veri ve embeddingleri yÃ¼kle
docs, ids, embeddings = load_data_and_embeddings(embedding_model)

st.caption(f"Veri tabanÄ±mÄ±zda {len(docs)} tarif bulunmaktadÄ±r. (LLM: {llm_model_name} | Embedding: {embedding_model_name})")

if "history" not in st.session_state:
    st.session_state.history = []

query = st.chat_input("Ne piÅŸirmek istersin? (Ã¶rn: IspanaklÄ± bir ÅŸey)")

if query:
    st.session_state.history.append({"role": "user", "content": query})

    with st.spinner("Tarif aranÄ±yor ve yanÄ±t oluÅŸturuluyor..."):
        try:
            # 1. Sorgu embed (Sentence Transformer ile)
            q_embed = np.array(embedding_model.encode(query))

            # 2. Cosine similarity hesapla
            if embeddings.shape[1] != q_embed.shape[0]:
                 st.error(f"Embedding boyutlarÄ± uyuÅŸmuyor! DÃ¶kÃ¼man: {embeddings.shape[1]}, Sorgu: {q_embed.shape[0]}")
                 st.stop()

            sims = [(i, cosine_similarity(q_embed, emb)) for i, emb in enumerate(embeddings)]
            sims = sorted(sims, key=lambda x: x[1], reverse=True)[:3] # En iyi 3 sonucu al

            # 3. En iyi dokÃ¼manlarÄ± (context) al
            # ğŸ›‘ DÃœZELTME: Benzerlik eÅŸiÄŸini kaldÄ±rdÄ±k! ArtÄ±k en benzer 3 her zaman alÄ±nacak.
            top_docs_content = [docs[i] for i, score in sims]

            if not top_docs_content:
                 # Bu durum artÄ±k sadece embedding/arama hatasÄ± olursa gerÃ§ekleÅŸmeli
                 llm_response = "ÃœzgÃ¼nÃ¼m, arama sÄ±rasÄ±nda bir sorun oluÅŸtu."
                 source_names = []
            else:
                source_names = [doc.split('\n')[0].replace('TARÄ°F ADI: ', '') for doc in top_docs_content]
                context = "\n---\n".join(top_docs_content)

                # 4. Prompt oluÅŸturma (Mistral/Zephyr formatÄ±)
                prompt = f"""<s>[INST] AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver.
EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece "ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m." diye yanÄ±tla. YanÄ±tÄ±nÄ± sadece TÃ¼rkÃ§e ver.

BAÄLAM:
{context}

SORU: {query} [/INST]
YANIT:"""

                # 5. Hugging Face Inference API'sine gÃ¶nderme
                response = hf_client.text_generation(
                    prompt,
                    max_new_tokens=300,
                    temperature=0.7,
                    top_p=0.9,
                    repetition_penalty=1.1,
                    do_sample=True
                )

                llm_response = response.strip()

            # GeÃ§miÅŸe ekle
            st.session_state.history.append({"role": "assistant", "content": llm_response, "sources": source_names})

        except Exception as e:
            # Hata yakalamayÄ± detaylandÄ±rdÄ±k
            tb_str = traceback.format_exc()
            error_msg = f"RAG/API HatasÄ± OluÅŸtu!\nDetaylar:\n{str(e)}\n\nTraceback:\n{tb_str}"
            st.error(error_msg)
            print(error_msg) # Loglara da yazdÄ±r
            st.session_state.history.append({"role": "assistant", "content": f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}", "sources": []})


# GeÃ§miÅŸi gÃ¶sterme
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg["role"] == "assistant" and msg.get("sources"):
            st.markdown("---")
            st.markdown("**KullanÄ±lan Kaynak Tarifler:**")
            sources = msg.get("sources", [])
            if sources:
                 for name in set(sources):
                     st.markdown(f"**-** *{name}*")
            else:
                 # EÄŸer kaynak yoksa (yani LLM context bulamadÄ±ysa veya hata oluÅŸtuysa)
                 st.markdown("*Bu yanÄ±t iÃ§in Ã¶zel bir tarif kullanÄ±lmadÄ± veya bulunamadÄ±.*")
