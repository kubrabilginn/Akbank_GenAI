
import streamlit as st
import os
import pandas as pd
from datasets import load_dataset
# LangChain bileÅŸenleri
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate

# ----------------------------------------------------------------------
# 1. API AnahtarÄ±nÄ±n GÃ¼venli KontrolÃ¼
# ----------------------------------------------------------------------

API_KEY = os.environ.get("GEMINI_API_KEY")

if not API_KEY:
    st.error("âŒ API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Cloud'da 'GEMINI_API_KEY' Secret'Ä±nÄ± ayarlayÄ±n.")
    st.stop()
# Hata Ã§Ã¶zÃ¼mÃ¼ iÃ§in langsmith takibini uygulama seviyesinde devre dÄ±ÅŸÄ± bÄ±rakma
os.environ["LANGCHAIN_TRACING_V2"] = "false"
os.environ["LANGCHAIN_SESSION"] = "false"# ----------------------------------------------------------------------
# 2. RAG BileÅŸenleri TanÄ±mlarÄ± (FONKSÄ°YONLAR BURADA BAÅLAR)
# ----------------------------------------------------------------------

# LLM ve Embedding Modelini TanÄ±mlama (DoÄŸrudan API AnahtarÄ± ile)
@st.cache_resource
def get_llm_model():
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0.2, 
        google_api_key=API_KEY 
    )

@st.cache_resource
def get_embedding_model():
    return GoogleGenerativeAIEmbeddings(
        model="text-embedding-004", 
        google_api_key=API_KEY 
    )

# Veri Seti YÃ¼kleme ve HazÄ±rlama
@st.cache_data
def load_and_prepare_data():
    dataset = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
    df = dataset.to_pandas()
    df['full_recipe'] = df.apply(
        lambda row: f"TARÄ°F ADI: {row['Title']}\nMALZEMELER: {', '.join(row['Ingredients'])}\nADIMLAR: {row['Instructions']}",
        axis=1
    )
    return df['full_recipe'].tolist()

# VektÃ¶r VeritabanÄ± ve Retriever'Ä± YÃ¼kleme/OluÅŸturma
@st.cache_resource
def get_retriever(recipe_docs):
    embedding_model = get_embedding_model()
    vectorstore = Chroma.from_texts(
        texts=recipe_docs, 
        embedding=embedding_model, 
        collection_name="yemek_tarifleri_rag"
    )
    return vectorstore.as_retriever(search_kwargs={"k": 3})

# RAG Zincirini Kurma (Cache dekoratÃ¶rÃ¼ kalÄ±cÄ± olarak kaldÄ±rÄ±ldÄ±)
def get_qa_chain(retriever):
    llm = get_llm_model()
    
    PROMPT_TEMPLATE = """AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver. 
    EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece "ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m." diye yanÄ±tla ve dÄ±ÅŸarÄ±dan bilgi ekleme.

    BAÄLAM:
    {context}

    SORU: {question}
    YANIT:"""
    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)

    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": custom_rag_prompt},
        return_source_documents=True
    )

# ----------------------------------------------------------------------
# 3. Streamlit Uygulama ArayÃ¼zÃ¼ (Ana Ä°ÅŸlem) - HER ÅEY BURADA BAÅLAR
# ----------------------------------------------------------------------

# 3.1 RAG BileÅŸenlerini YÃ¼kleme/Kurma
# Bu Ã§aÄŸÄ±rmalar artÄ±k fonksiyon tanÄ±mlarÄ±nÄ±n altÄ±nda yapÄ±ldÄ±ÄŸÄ± iÃ§in NameError Ã§Ã¶zÃ¼ldÃ¼.
recipe_docs = load_and_prepare_data()
retriever = get_retriever(recipe_docs)
qa_chain = get_qa_chain(retriever)


# 3.2 ArayÃ¼z BaÅŸlÄ±klarÄ±
st.set_page_config(page_title="Akbank GenAI Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (RAG)")
st.caption(f"Veri tabanÄ±mÄ±zda {len(recipe_docs)} tarif bulunmaktadÄ±r. (Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir)")
st.divider()

if 'history' not in st.session_state:
    st.session_state.history = []

# KullanÄ±cÄ± GiriÅŸi
user_query = st.chat_input("Tarif sorunuzu girin (Ã–rn: Ispanak ve peynirle ne yapabilirim?)")

if user_query:
    # KullanÄ±cÄ± sorgusunu kaydet
    st.session_state.history.append({"role": "user", "content": user_query})
    
    with st.spinner(f"'{user_query}' iÃ§in tarif aranÄ±yor..."):
        try:
            # RAG Zincirini Ã‡alÄ±ÅŸtÄ±rma
            response = qa_chain.invoke({"query": user_query})
            llm_response = response['result']
            source_docs = response['source_documents']

            # YanÄ±tÄ± ve kaynaklarÄ± geÃ§miÅŸe ekleme
            st.session_state.history.append({"role": "assistant", "content": llm_response, "sources": source_docs})

        except Exception as e:
            error_msg = f"API HatasÄ±: LÃ¼tfen API anahtarÄ±nÄ±zÄ±n Streamlit Secrets'ta doÄŸru ayarlandÄ±ÄŸÄ±ndan emin olun. Hata: {e}"
            st.session_state.history.append({"role": "assistant", "content": error_msg, "sources": []})

# GeÃ§miÅŸi gÃ¶sterme
for message in st.session_state.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # YanÄ±tta kullanÄ±lan kaynaklarÄ± gÃ¶ster
        if message["role"] == "assistant" and "sources" in message and message["sources"]:
            st.markdown("---")
            st.markdown("**KullanÄ±lan Kaynak Tarifler:**")
            source_names = [doc.page_content.split('\n')[0].replace('TARÄ°F ADI: ', '') for doc in message["sources"]]
            for name in set(source_names):
                st.markdown(f"**-** *{name}*")
