import streamlit as st
import os
import pandas as pd
from datasets import load_dataset
import chromadb # ChromaDB'yi manuel de dahil ediyoruz

# LangChain Ã‡ekirdek ve BaÄŸlayÄ±cÄ±larÄ± (requirements.txt'den geliyor)
# app.py dosyasÄ±nÄ±n baÅŸÄ±ndaki importlarÄ± bulun (YaklaÅŸÄ±k 5. satÄ±r):

# Eski HatalÄ± Import Zinciri:
# from langchain_chroma import Chroma
# from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
# from langchain.chains import RetrievalQA

# YENÄ° VE DÃœZELTÄ°LMÄ°Å IMPORT ZÄ°NCÄ°RÄ°:
from langchain_chroma import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains.retrieval_qa.base import RetrievalQA

# KRÄ°TÄ°K EKSÄ°K IMPORT: Bu satÄ±r, hatayÄ± Ã§Ã¶zer
from langchain_core.documents import Document
# ----------------------------------------------------------------------
# 1. API AnahtarÄ±nÄ±n GÃ¼venli KontrolÃ¼
# ----------------------------------------------------------------------

API_KEY = os.environ.get("GEMINI_API_KEY")

if not API_KEY:
    st.error("âŒ API AnahtarÄ± bulunamadÄ±. LÃ¼tfen Streamlit Secrets'ta 'GEMINI_API_KEY' Secret'Ä±nÄ± ayarlayÄ±n.")
    st.stop()

# Ortam deÄŸiÅŸkenini (LangSmith'i engellemek iÃ§in) tekrar ayarlÄ±yoruz
os.environ["LANGCHAIN_TRACING_V2"] = "false"


# ----------------------------------------------------------------------
# 2. RAG BileÅŸenleri TanÄ±mlarÄ± (Cache ile HÄ±zlandÄ±rma)
# ----------------------------------------------------------------------

# Veri Seti YÃ¼kleme ve HazÄ±rlama
@st.cache_data
def load_and_prepare_data():
    # Load ve hazÄ±rlÄ±k kÄ±smÄ± aynÄ± kalÄ±r
    dataset = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
    df = dataset.to_pandas()
    df['full_recipe'] = df.apply(
        lambda row: f"TARÄ°F ADI: {row['Title']}\nMALZEMELER: {', '.join(row['Ingredients'])}\nADIMLAR: {row['Instructions']}",
        axis=1
    )
    # LangChain'in Document objesi iÃ§in gerekli olan formatlama (metadata iÃ§in)
    from langchain_core.documents import Document
    docs = [Document(page_content=recipe) for recipe in df['full_recipe']]
    return docs, df['full_recipe'].tolist() # Ä°htiyaÃ§ duyulursa eski liste de dÃ¶ner

# Embedding Modelini TanÄ±mlama
@st.cache_resource
def get_embedding_model():
    return GoogleGenerativeAIEmbeddings(
        model="embedding-001", 
        google_api_key=API_KEY 
    )

# ChromaDB ve Retriever'Ä± Kurma (LANGCHAIN ÃœZERÄ°NDEN)
@st.cache_resource
def get_retriever(docs):
    embedding_model = get_embedding_model()
    
    # LangChain, Chroma'yÄ± baÅŸlatÄ±rken gerekli tÃ¼m kontrolleri (izin, name) kendisi yapar
    vectorstore = Chroma.from_documents(
        documents=docs, 
        embedding=embedding_model, 
        collection_name="yemek_tarifleri_rag",
        # KalÄ±cÄ±lÄ±ÄŸÄ± kapatmak iÃ§in None kullanÄ±yoruz, bellek iÃ§i Ã§alÄ±ÅŸÄ±r
        persist_directory=None 
    )
    return vectorstore.as_retriever(search_kwargs={"k": 3})

# LLM ve RAG Zincirini Kurma
@st.cache_resource
def get_qa_chain(retriever):
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0.2, 
        google_api_key=API_KEY 
    )

    PROMPT_TEMPLATE = """AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver. 
    EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece "ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m." diye yanÄ±tla.

    BAÄLAM:
    {context}

    SORU: {question}
    YANIT:"""
    
    from langchain.prompts import PromptTemplate # Geri getirdiÄŸimiz paketlerden import et
    custom_rag_prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": custom_rag_prompt},
        return_source_documents=True
    )
    return qa_chain

# ----------------------------------------------------------------------
# 3. Streamlit Uygulama ArayÃ¼zÃ¼ (Ana Ä°ÅŸlem)
# ----------------------------------------------------------------------

# RAG bileÅŸenlerini yÃ¼kle
docs, _ = load_and_prepare_data()
retriever = get_retriever(docs)
qa_chain = get_qa_chain(retriever)

# ... (KullanÄ±cÄ± arayÃ¼z kodu aynÄ± kalÄ±r) ...

st.set_page_config(page_title="Akbank GenAI Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (LangChain RAG)")
st.caption(f"Veri tabanÄ±mÄ±zda {len(docs)} tarif bulunmaktadÄ±r. (Gemini 2.5 Flash ile gÃ¼Ã§lendirilmiÅŸtir)")
st.divider()

if 'history' not in st.session_state:
    st.session_state.history = []

user_query = st.chat_input("Tarif sorunuzu girin (Ã–rn: Ispanak ve peynirle ne yapabilirim?)")

if user_query:
    st.session_state.history.append({"role": "user", "content": user_query})
    
    with st.spinner(f"'{user_query}' iÃ§in tarif aranÄ±yor..."):
        try:
            # LangChain zincirini Ã§alÄ±ÅŸtÄ±rma
            response = qa_chain.invoke({"query": user_query})
            
            llm_response = response['result']
            source_docs = response['source_documents']
            
            # Kaynak metinleri iÅŸleme
            source_names = [doc.page_content.split('\n')[0].replace('TARÄ°F ADI: ', '') for doc in source_docs]

            st.session_state.history.append({"role": "assistant", "content": llm_response, "sources": source_names})

        except Exception as e:
            error_msg = f"RAG/API HatasÄ±: LÃ¼tfen API anahtarÄ±nÄ±zÄ±n doÄŸru olduÄŸundan emin olun. Detay: {e}"
            st.session_state.history.append({"role": "assistant", "content": error_msg, "sources": []})

# GeÃ§miÅŸi gÃ¶sterme
for message in st.session_state.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        if message["role"] == "assistant" and message.get("sources"):
            st.markdown("---")
            st.markdown("**KullanÄ±lan Kaynak Tarifler:**")
            for name in set(message["sources"]):
                st.markdown(f"**-** *{name}*")
