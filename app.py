import streamlit as st
import os
import pandas as pd
import numpy as np
from typing import List

# ğŸ›‘ DÃœZELTME: DoÄŸru kÃ¼tÃ¼phane adÄ±nÄ± import ediyoruz
import google.generativeai as genai 
# from google.genai import types <-- ArtÄ±k buna gerek yok veya farklÄ± import edilmeli

# ------------------------------------------------
# API Key kontrolÃ¼ (Secrets'tan okunur)
# ------------------------------------------------
API_KEY = os.environ.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("âŒ API AnahtarÄ± bulunamadÄ±. Streamlit Secrets bÃ¶lÃ¼mÃ¼ne GEMINI_API_KEY ekleyin.")
    st.stop()

# ğŸ›‘ genai.configure() Ã§aÄŸrÄ±sÄ±nÄ± tamamen kaldÄ±rdÄ±k.
# KÃ¼tÃ¼phanenin API_KEY'i ortam deÄŸiÅŸkeninden otomatik almasÄ±nÄ± bekliyoruz.

embedding_model_name = "models/embedding-001"
llm_model_name = "gemini-1.5-flash-latest" # Daha gÃ¼ncel ve genellikle daha iyi model

# ------------------------------------------------
# Tarifleri yÃ¼kleme (DeÄŸiÅŸiklik yok)
# ------------------------------------------------
from datasets import load_dataset

@st.cache_data(show_spinner="Tarifler yÃ¼kleniyor...")
def load_recipes() -> list[str]:
    ds = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
    recipes = []
    for item in ds:
        title = item.get("Title", "")
        ingredients = item.get("Ingredients", [])
        if isinstance(ingredients, list):
            ingredients = ", ".join(ingredients)
        instructions = item.get("Instructions", "")
        full_recipe = f"TARÄ°F ADI: {title}\nMALZEMELER: {ingredients}\nADIMLAR: {instructions}"
        recipes.append(full_recipe)
    return recipes

# ------------------------------------------------
# Veri ve Embedding Cache (configure olmadan)
# ------------------------------------------------
@st.cache_data(show_spinner="Veriler ve embeddingler hazÄ±rlanÄ±yor...")
def load_data_and_embeddings():
    recipe_docs = load_recipes()
    doc_ids = [f"doc_{i}" for i in range(len(recipe_docs))]

    try:
        # API anahtarÄ± ortam deÄŸiÅŸkeninden otomatik alÄ±nmalÄ±
        # GÃ¼venlik iÃ§in configure'u buraya taÅŸÄ±yalÄ±m
        genai.configure(api_key=API_KEY)
        result = genai.embed_content(
            model=embedding_model_name,
            content=recipe_docs,
            task_type="RETRIEVAL_DOCUMENT"
        )
        embeds = result['embedding']
    except AttributeError as ae:
         st.error(f"SDK HatasÄ±: GÃ¶mme fonksiyonu bulunamadÄ± veya yanlÄ±ÅŸ Ã§aÄŸrÄ±ldÄ±. Hata: {ae}. KÃ¼tÃ¼phane sÃ¼rÃ¼mÃ¼nÃ¼ kontrol edin.")
         st.stop()
    except Exception as e:
        if "API_KEY" in str(e).upper():
             st.error(f"Embedding oluÅŸturulurken API AnahtarÄ± hatasÄ±: {str(e)}. LÃ¼tfen Secrets'Ä± kontrol edin.")
        else:
             st.error(f"Embedding oluÅŸturulurken hata: {str(e)}")
        st.stop()

    return recipe_docs, doc_ids, np.array(embeds)


# âœ… KosinÃ¼s benzerliÄŸi (DeÄŸiÅŸiklik yok)
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    # NaN kontrolÃ¼ ekleyelim
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return np.dot(a, b) / (norm_a * norm_b)

# ------------------------------------------------
# UI
# ------------------------------------------------
st.set_page_config(page_title="Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (DoÄŸrudan SDK RAG)")
st.divider()

# Veri ve embeddingleri yÃ¼kle
docs, ids, embeddings = load_data_and_embeddings()

st.caption(f"Veri tabanÄ±mÄ±zda {len(docs)} tarif bulunmaktadÄ±r. ({llm_model_name} ile gÃ¼Ã§lendirilmiÅŸtir)")

if "history" not in st.session_state:
    st.session_state.history = []

query = st.chat_input("Ne piÅŸirmek istersin? (Ã¶rn: IspanaklÄ± bir ÅŸey)")

if query:
    st.session_state.history.append({"role": "user", "content": query})

    with st.spinner("Tarif aranÄ±yor ve yanÄ±t oluÅŸturuluyor..."):
        try:
            # 1. Sorgu embed (configure olmadan)
            q_res = genai.embed_content(
                model=embedding_model_name,
                content=query,
                task_type="RETRIEVAL_QUERY"
            )
            q_embed = np.array(q_res['embedding'])

            # 2. Cosine similarity hesapla (DeÄŸiÅŸiklik yok)
            sims = [(i, cosine_similarity(q_embed, emb)) for i, emb in enumerate(embeddings)]
            sims = sorted(sims, key=lambda x: x[1], reverse=True)[:3]

            # 3. En iyi dokÃ¼manlarÄ± al (DeÄŸiÅŸiklik yok)
            top_docs_content = [docs[i] for i, _ in sims]
            source_names = [doc.split('\n')[0].replace('TARÄ°F ADI: ', '') for doc in top_docs_content]
            context = "\n---\n".join(top_docs_content)

            # 4. Prompt oluÅŸturma (DeÄŸiÅŸiklik yok)
            prompt = f"""AÅŸaÄŸÄ±daki baÄŸlamda sana verilen yemek tariflerini kullanarak, kullanÄ±cÄ±nÄ±n sorusuna detaylÄ± ve yardÄ±mcÄ± bir ÅŸekilde yanÄ±t ver.
EÄŸer baÄŸlamda uygun tarif bulamazsan, kibarca sadece "ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m." diye yanÄ±tla.

BAÄLAM:
{context}

SORU: {query}
YANIT:"""

            # 5. LLM'ye gÃ¶nderme (configure olmadan)
            llm = genai.GenerativeModel(model_name=llm_model_name)
            # GÃ¼venlik ayarlarÄ±nÄ± gevÅŸetme (opsiyonel, bazen yanÄ±tlarÄ± engeller)
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
            response = llm.generate_content(prompt, safety_settings=safety_settings)

            # YanÄ±tÄ± gÃ¼venli bir ÅŸekilde al
            try:
                llm_response = response.text
            except ValueError:
                llm_response = "Modelden yanÄ±t alÄ±namadÄ± veya yanÄ±t engellendi."
                # Engelleme nedenini logla (opsiyonel)
                # print(response.prompt_feedback)


            # GeÃ§miÅŸe ekle
            st.session_state.history.append({"role": "assistant", "content": llm_response, "sources": source_names})

        except AttributeError as ae:
             st.error(f"SDK HatasÄ±: Gerekli fonksiyon bulunamadÄ± veya yanlÄ±ÅŸ Ã§aÄŸrÄ±ldÄ±. Hata: {ae}. KÃ¼tÃ¼phane sÃ¼rÃ¼mÃ¼nÃ¼ kontrol edin.")
             st.session_state.history.append({"role": "assistant", "content": f"ÃœzgÃ¼nÃ¼m, SDK hatasÄ± oluÅŸtu: {ae}", "sources": []})
        except Exception as e:
            if "API_KEY" in str(e).upper() or "permission denied" in str(e).lower():
                 st.error(f"RAG/API HatasÄ±: {str(e)}. LÃ¼tfen Secrets bÃ¶lÃ¼mÃ¼ndeki GEMINI_API_KEY'i kontrol edin.")
            else:
                 st.error(f"RAG/API HatasÄ±: {str(e)}")
            st.session_state.history.append({"role": "assistant", "content": f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {e}", "sources": []})


# GeÃ§miÅŸi gÃ¶sterme (DeÄŸiÅŸiklik yok)
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg["role"] == "assistant" and msg.get("sources"):
            st.markdown("---")
            st.markdown("**KullanÄ±lan Kaynak Tarifler:**")
            for name in set(msg.get("sources", [])):
                st.markdown(f"**-** *{name}*")
