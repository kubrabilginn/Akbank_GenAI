import streamlit as st
import os
import pandas as pd
import numpy as np
from typing import List

from google import genai
from google.genai import types

# ------------------------------------------------
# API Key kontrolÃ¼
# ------------------------------------------------
API_KEY = os.environ.get("GEMINI_API_KEY")
if not API_KEY:
    st.error("âŒ API AnahtarÄ± bulunamadÄ±. Streamlit Secrets bÃ¶lÃ¼mÃ¼ne GEMINI_API_KEY ekleyin.")
    st.stop()

client = genai.Client(api_key=API_KEY)
embedding_model = "models/text-embedding-004"
llm_model = "gemini-2.5-flash"

# ------------------------------------------------
# Tarifleri yÃ¼kleme
# ------------------------------------------------
from datasets import load_dataset

@st.cache_data(show_spinner="Tarifler yÃ¼kleniyor...")
def load_recipes() -> list[str]:
    """
    Hugging Face datasets Ã¼zerinden yemek tariflerini yÃ¼kler.
    Ä°lk 200 tarifi alÄ±r ve Title + Ingredients + Instructions ÅŸeklinde birleÅŸtirir.
    """
    ds = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
    recipes = []

    for item in ds:
        title = item.get("Title", "")
        ingredients = item.get("Ingredients", "")
        instructions = item.get("Instructions", "")
        full_recipe = f"{title}\nMalzemeler: {ingredients}\nYapÄ±lÄ±ÅŸÄ±: {instructions}"
        recipes.append(full_recipe)
    
    return recipes

# ------------------------------------------------
# Veri ve Embedding Cache
# ------------------------------------------------
@st.cache_data(show_spinner="Veriler ve embeddingler yÃ¼kleniyor...")
def load_data_and_embeddings():
    recipe_docs = load_recipes()
    doc_ids = [f"doc_{i}" for i in range(len(recipe_docs))]
    embeds = []

    try:
        # Her bir metin iÃ§in embed oluÅŸtur
        for doc in recipe_docs:
            res = client.models.embed_content(
                model=embedding_model,
                text=doc  # artÄ±k 'text' parametresi kullanÄ±lÄ±yor
            )
            embeds.append(res.embedding.values)
    except Exception as e:
        st.error(f"Embedding oluÅŸturulurken hata: {str(e)}")
        raise e

    return recipe_docs, doc_ids, embeds


# âœ… KosinÃ¼s benzerliÄŸi
def cosine_similarity(a: List[float], b: List[float]) -> float:
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# ------------------------------------------------
# UI
# ------------------------------------------------
st.set_page_config(page_title="Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Yemek Tarifleri Chatbotu (Chromaâ€™sÄ±z tam uyumlu)")
st.divider()

docs, ids, embeddings = load_data_and_embeddings()

if "history" not in st.session_state:
    st.session_state.history = []

query = st.chat_input("Ne piÅŸirmek istersin? (Ã¶rn: IspanaklÄ± bir ÅŸey)")

if query:
    st.session_state.history.append({"role": "user", "content": query})

    with st.spinner("Tarif aranÄ±yor..."):
    # Sorgu iÃ§in embedding
    q_res = client.models.embed_content(
        model=embedding_model,
        text=query   # 'text' parametresi tekil metin iÃ§in kullanÄ±lÄ±yor
    )
    q_embed = q_res.embedding.values


        sims = [(i, cosine_similarity(q_embed, emb)) for i, emb in enumerate(embeddings)]
        sims = sorted(sims, key=lambda x: x[1], reverse=True)[:3]

        top_docs = [docs[i] for i, _ in sims]

        if not top_docs:
            answer = "ÃœzgÃ¼nÃ¼m, uygun tarif bulamadÄ±m."
        else:
            prompt = f"""
AÅŸaÄŸÄ±da yemek tarifleri var. KullanÄ±cÄ±nÄ±n sorusuna yardÄ±mcÄ± ol:

BAÄLAM:
{"\n---\n".join(top_docs)}

SORU: {query}
YANIT:
"""
            answer = client.models.generate_content(
                model=llm_model,
                contents=prompt
            ).text

        st.session_state.history.append({"role": "assistant", "content": answer})

for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
