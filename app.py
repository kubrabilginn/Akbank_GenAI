import streamlit as st
import os
import pandas as pd
import numpy as np
from typing import List
import traceback # Hata ayÄ±klama iÃ§in

# Gerekli KÃ¼tÃ¼phaneler
from sentence_transformers import SentenceTransformer # Embedding iÃ§in
from groq import Groq                             # LLM iÃ§in
from datasets import load_dataset

# ------------------------------------------------
# API Key kontrolÃ¼ (ArtÄ±k Groq iÃ§in)
# ------------------------------------------------
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
if not GROQ_API_KEY:
    st.error("âŒ Groq API AnahtarÄ± bulunamadÄ±. Streamlit Secrets bÃ¶lÃ¼mÃ¼ne GROQ_API_KEY ekleyin.")
    st.stop()

# Groq Ä°stemcisini baÅŸlatma
try:
    groq_client = Groq(api_key=GROQ_API_KEY)
except Exception as e:
    st.error(f"Groq istemcisi baÅŸlatÄ±lÄ±rken hata: {e}")
    st.stop()

# Model isimleri
embedding_model_name = 'all-MiniLM-L6-v2' # HF Embedding
llm_model_name = "llama-3.1-8b-instant" # GÃ¼ncel ve aktif Groq modeli
# ------------------------------------------------
# Sentence Transformer Modelini YÃ¼kleme (Cache ile)
# ------------------------------------------------
@st.cache_resource(show_spinner="Embedding modeli yÃ¼kleniyor...")
def load_embedding_model():
    """Hugging Face'den Sentence Transformer modelini yÃ¼kler."""
    try:
        model = SentenceTransformer(embedding_model_name)
        return model
    except Exception as e:
        st.error(f"Sentence Transformer modeli yÃ¼klenirken hata: {e}")
        st.stop()

# ------------------------------------------------
# Tarifleri yÃ¼kleme (DeÄŸiÅŸiklik yok)
# ------------------------------------------------
@st.cache_data(show_spinner="Tarifler yÃ¼kleniyor...")
def load_recipes() -> list[str]:
    """Hugging Face datasets Ã¼zerinden yemek tariflerini yÃ¼kler (200 adet)."""
    try:
        ds = load_dataset("Hieu-Pham/kaggle_food_recipes", split="train[:200]")
        recipes = []
        for item in ds:
            title = item.get("Title", "")
            ingredients = item.get("Ingredients", [])
            if isinstance(ingredients, list):
                ingredients = ", ".join(ingredients)
            else:
                ingredients = str(ingredients)
            instructions = item.get("Instructions", "")
            full_recipe = f"TARÄ°F ADI: {title}\nMALZEMELER: {ingredients}\nADIMLAR: {instructions}"
            recipes.append(full_recipe)
        if not recipes:
             st.error("Tarifler yÃ¼klenemedi veya veri seti boÅŸ.")
             st.stop()
        return recipes
    except Exception as e:
        st.error(f"Veri seti yÃ¼klenirken hata: {e}")
        st.stop()


# ------------------------------------------------
# Veri ve Embedding Cache (Sentence Transformer ile)
# ------------------------------------------------
@st.cache_data(show_spinner="Veriler ve embeddingler hazÄ±rlanÄ±yor...")
def load_data_and_embeddings(_embedding_model):
    """Tarifleri yÃ¼kler ve Sentence Transformer ile embed eder."""
    recipe_docs = load_recipes()
    if not recipe_docs:
        st.error("Tarif dokÃ¼manlarÄ± boÅŸ, embedding oluÅŸturulamÄ±yor.")
        st.stop()

    doc_ids = [f"doc_{i}" for i in range(len(recipe_docs))]
    try:
        embeds = _embedding_model.encode(recipe_docs, show_progress_bar=False)
        if embeds is None or len(embeds) == 0:
             st.error("Embedding oluÅŸturma baÅŸarÄ±sÄ±z oldu, boÅŸ sonuÃ§ dÃ¶ndÃ¼.")
             st.stop()
        embeds_np = np.array(embeds)
        return recipe_docs, doc_ids, embeds_np
    except Exception as e:
        st.error(f"Embedding oluÅŸturulurken hata: {str(e)}")
        st.stop()


# âœ… KosinÃ¼s benzerliÄŸi (DeÄŸiÅŸiklik yok)
def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    dot_product = np.dot(a.astype(np.float32), b.astype(np.float32))
    return dot_product / (norm_a * norm_b)

# ------------------------------------------------
# UI
# ------------------------------------------------
st.set_page_config(page_title="Yemek Tarifleri Chatbotu", layout="wide")
st.title("ğŸ½ï¸ Akbank GenAI Yemek Tarifleri Chatbotu (HF Embedding + Groq LLM)")
st.divider()

# Embedding modelini yÃ¼kle
embedding_model = load_embedding_model()
# Veri ve embeddingleri yÃ¼kle
docs, ids, embeddings = load_data_and_embeddings(embedding_model)

st.caption(f"Veri tabanÄ±mÄ±zda {len(docs)} tarif bulunmaktadÄ±r. (LLM: {llm_model_name} @ Groq | Embedding: {embedding_model_name})")

if "history" not in st.session_state:
    st.session_state.history = []

query = st.chat_input("Ne piÅŸirmek istersin? (Ã¶rn: IspanaklÄ± bir ÅŸey)")

if query:
    st.session_state.history.append({"role": "user", "content": query})

    with st.spinner("Tarif aranÄ±yor ve yanÄ±t oluÅŸturuluyor..."):
        try:
            # 1. Sorgu embed (Sentence Transformer ile)
            q_embed = np.array(embedding_model.encode(query))

            # 2. Cosine similarity hesapla
            if embeddings.shape[1] != q_embed.shape[0]:
                 st.error(f"Embedding boyutlarÄ± uyuÅŸmuyor! DÃ¶kÃ¼man: {embeddings.shape[1]}, Sorgu: {q_embed.shape[0]}")
                 st.stop()

            sims = [(i, cosine_similarity(q_embed, emb)) for i, emb in enumerate(embeddings)]
            sims = sorted(sims, key=lambda x: x[1], reverse=True)[:3]

            # 3. En iyi dokÃ¼manlarÄ± (context) al
            top_docs_content = [docs[i] for i, score in sims]
            if not top_docs_content:
                 llm_response = "ÃœzgÃ¼nÃ¼m, bu isteÄŸe uygun bir tarif bulamadÄ±m."
                 source_names = []
            else:
                source_names = [doc.split('\n')[0].replace('TARÄ°F ADI: ', '') for doc in top_docs_content]
                context = "\n---\n".join(top_docs_content)

                # 4. Prompt oluÅŸturma (Groq iÃ§in mesaj formatÄ±)
                # Llama3 ve Mixtral genellikle bu formatÄ± anlar
                system_prompt = """Sen yardÄ±msever bir yemek tarifi asistanÄ±sÄ±n. Sana verilen baÄŸlamdaki tarifleri kullanarak kullanÄ±cÄ±nÄ±n sorusuna cevap ver. EÄŸer baÄŸlamda uygun tarif yoksa, sadece 'ÃœzgÃ¼nÃ¼m, veri tabanÄ±mda bu isteÄŸe uygun bir tarif bulamadÄ±m.' de. YanÄ±tÄ±nÄ± sadece TÃ¼rkÃ§e ver."""
                user_prompt = f"""BAÄLAM:
{context}

SORU: {query}"""

                # 5. Groq API'sine gÃ¶nderme
                chat_completion = groq_client.chat.completions.create(
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": user_prompt,
                        }
                    ],
                    model=llm_model_name,
                    temperature=0.7,
                    max_tokens=300,
                    top_p=0.9,
                )

                llm_response = chat_completion.choices[0].message.content.strip()

            # GeÃ§miÅŸe ekle
            st.session_state.history.append({"role": "assistant", "content": llm_response, "sources": source_names})

        except Exception as e:
            tb_str = traceback.format_exc()
            error_msg = f"RAG/API HatasÄ± OluÅŸtu!\nDetaylar:\n{str(e)}\n\nTraceback:\n{tb_str}"
            st.error(error_msg)
            print(error_msg) # Loglara da yazdÄ±r
            st.session_state.history.append({"role": "assistant", "content": f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}", "sources": []})


# GeÃ§miÅŸi gÃ¶sterme (DeÄŸiÅŸiklik yok)
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if msg["role"] == "assistant" and msg.get("sources"):
            st.markdown("---")
            st.markdown("**KullanÄ±lan Kaynak Tarifler:**")
            sources = msg.get("sources", [])
            if sources:
                 for name in set(sources):
                     st.markdown(f"**-** *{name}*")
            else:
                 st.markdown("*Bu yanÄ±t iÃ§in Ã¶zel bir tarif kullanÄ±lmadÄ± veya bulunamadÄ±.*")
